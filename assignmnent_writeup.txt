
Kindly execuse me for my bad presentation of the assignment, badly short of time so just writing the main steps I did and though to solve the problem.

-> The training data had 160 features present
	-> A quick inspection from summary command showed that majority of columns are either NA or not varying much
	-> Moreover we know the accuracy of the model goes down after a point if we keep increasing no. of features 

-> So first action was to cleanup up the redudndant features
	-> First used the nearZeroVars method
		-> populated list of names which had FALSE NZV (near zero value)
		-> came down from 160 -> 106
	-> Still columns with zero variance were present
		-> So applied the var method on the training data
		-> Created a list of variable which did not had zero variance
		-> came down from 106 -> 59
	-> Also removed the 2 factor variables user_name and vtd_timestamp as they were not of any use
		-> So final features list came down from 59 -> 57
	-> The number of features were still on higher side
		-> Plotted featureplot to see is there a clear relation between the classe variable and majority of these 57, it was evident that not many have a direct clear relation
	-> So applied PCA to capture 80% variance
		-> Number of features came down from 57 -> 15

-> Since the variable to predict "classe" was a factor variable so we cannot fit a linear model which observers the change in output y for every change in input x
	-> So discarded all linear model algorithms
	-> Trees seemed to be the best choice, so tried RandomForest

-> To avoid bias towards the training data and to reduce out of sample error used the "Bagging approach" and used "treebag" algorithm to predict

